# DIAGNÃ“STICO: generate-plan Edge Function Timeout

**Data:** 04/12/2025  
**Status:** ğŸ”´ CRÃTICO - Timeout constante (>10s)  
**Protocolo:** HOTFIX PROTOCOL 1.0 - SeÃ§Ã£o 4.2 (DiagnÃ³stico da causa raiz)

---

## ğŸ” CAUSA RAIZ IDENTIFICADA

### Problema Principal: Prompts Extremamente Longos

A Edge Function `generate-plan` estÃ¡ enviando **prompts gigantescos** para a OpenAI API:

1. **Prompt Physical:** ~200 linhas de JSON estruturado detalhado
2. **Prompt Nutritional:** ~150 linhas com 4 semanas completas
3. **Prompt Emotional:** ~100 linhas com tÃ©cnicas detalhadas
4. **Prompt Spiritual:** ~100 linhas com prÃ¡ticas diÃ¡rias

**Modelo usado:** `gpt-4o-mini`

### AnÃ¡lise de Tempo

```
Tempo esperado: < 5s
Tempo real: > 10s (TIMEOUT)
LatÃªncia mÃ©dia outras functions: ~1.2s
```

### Fatores Contribuintes

1. **Tokens excessivos no prompt** (estimativa: 3.000-5.000 tokens)
2. **response_format: json_object** forÃ§a estrutura rÃ­gida (mais lento)
3. **Temperature 0.4** (baixa, mas nÃ£o Ã© o problema principal)
4. **4 tipos de planos diferentes** (physical, nutritional, emotional, spiritual)
5. **Feedbacks pendentes** adicionam mais contexto ao prompt

### Por que estÃ¡ demorando?

- OpenAI API leva mais tempo para gerar JSON estruturado complexo
- Prompts longos aumentam tempo de processamento
- gpt-4o-mini Ã© rÃ¡pido, mas JSON complexo adiciona overhead
- Feedback loops adicionam contexto extra ao prompt

---

## ğŸ’¡ SOLUÃ‡Ã•ES POSSÃVEIS (Ordenadas por Impacto/EsforÃ§o)

### âœ… SOLUÃ‡ÃƒO 1: Simplificar Prompts (RÃPIDO - 20 min)

**Impacto:** ALTO  
**EsforÃ§o:** BAIXO  
**Risco:** BAIXO

**AÃ§Ã£o:**
- Reduzir exemplos JSON de 4 semanas para 2 semanas
- Remover repetiÃ§Ãµes e instruÃ§Ãµes redundantes
- Manter apenas diretrizes essenciais
- Reduzir de ~200 linhas para ~100 linhas

**Estimativa de reduÃ§Ã£o:** 40-50% no tempo de resposta

---

### âœ… SOLUÃ‡ÃƒO 2: Aumentar Timeout da Edge Function (IMEDIATO - 2 min)

**Impacto:** MÃ‰DIO (alivia sintoma, nÃ£o resolve causa)  
**EsforÃ§o:** MUITO BAIXO  
**Risco:** BAIXO

**AÃ§Ã£o:**
```typescript
// No arquivo index.ts, adicionar timeout configurado
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 25000); // 25s ao invÃ©s de 10s

const response = await fetch("https://api.openai.com/v1/chat/completions", {
  signal: controller.signal,
  // ... resto
});
clearTimeout(timeoutId);
```

**Estimativa:** Permite funÃ§Ã£o completar sem timeout (nÃ£o otimiza velocidade)

---

### âš ï¸ SOLUÃ‡ÃƒO 3: Dividir em Micro-GeraÃ§Ãµes (MÃ‰DIO - 1h)

**Impacto:** MUITO ALTO  
**EsforÃ§o:** ALTO  
**Risco:** MÃ‰DIO

**AÃ§Ã£o:**
- Gerar estrutura bÃ¡sica primeiro (5-7s)
- Enriquecer com detalhes em segunda chamada (5-7s)
- Total: 10-14s, mas mais confiÃ¡vel

**Problema:** Adiciona complexidade

---

### âš ï¸ SOLUÃ‡ÃƒO 4: Streaming Response (COMPLEXO - 2-3h)

**Impacto:** ALTO  
**EsforÃ§o:** MUITO ALTO  
**Risco:** ALTO

**AÃ§Ã£o:**
- Usar `stream: true` na OpenAI API
- Processar JSON incrementalmente
- Requer refatoraÃ§Ã£o significativa

**Problema:** Frontend precisa lidar com streaming

---

## ğŸ¯ RECOMENDAÃ‡ÃƒO IMEDIATA

### Aplicar SOLUÃ‡ÃƒO 1 + SOLUÃ‡ÃƒO 2 em paralelo

**Plano de AÃ§Ã£o:**

1. **[2 min]** Aumentar timeout para 25s (workaround temporÃ¡rio)
2. **[20 min]** Simplificar todos os 4 prompts (physical, nutritional, emotional, spiritual)
3. **[10 min]** Testar localmente com `curl` simulando chamada real
4. **[5 min]** Deploy e validar com health check

**Tempo total:** ~40 minutos  
**ReduÃ§Ã£o esperada:** De >10s para ~5-7s (dentro do aceitÃ¡vel)

---

## ğŸ“Š VALIDAÃ‡ÃƒO

### Antes da correÃ§Ã£o:
```bash
ğŸ“¡ Testando generate-plan... âŒ TIMEOUT (10013ms)
```

### Depois da correÃ§Ã£o (esperado):
```bash
ğŸ“¡ Testando generate-plan... âœ… 200 (5000-7000ms)
```

### CritÃ©rios de Sucesso:
- âœ… LatÃªncia < 8s
- âœ… Taxa de sucesso > 95%
- âœ… JSON vÃ¡lido retornado
- âœ… Planos mantÃªm qualidade (4 semanas, exercÃ­cios completos)

---

## ğŸš¨ PRÃ“XIMOS PASSOS (Protocolo 4.3)

1. Criar branch: `hotfix/generate-plan-timeout`
2. Implementar SOLUÃ‡ÃƒO 1 + 2
3. Testar localmente
4. Deploy controlado
5. Validar com health check
6. Atualizar #update_log

---

**Status:** DIAGNÃ“STICO COMPLETO - PRONTO PARA CORREÃ‡ÃƒO
